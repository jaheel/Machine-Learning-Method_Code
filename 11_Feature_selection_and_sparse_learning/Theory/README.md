# 特征选择与稀疏学习

特征(feature)

相关特征(relevant feature)

无关特征(irrelevant feature)

特征选择(feature selection)

> 从给定的特征集合中选择出相关特征子集的过程



冗余特征(redundant feature)



“前向”搜索

> 逐渐增加相关特征的策略

“后向”搜索

> 每次尝试去掉一个无关特征，逐渐减少特征

“双向”搜索

> 将前向和后向搜索结合起来



## 过滤式选择

先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。

度量方法：”相关统计量“



## 包裹式选择

直接把最终将要使用的学习器的性能作为特征子集的评价标准

目的：为给定学习器选择最有利于其性能、”量身定做“的特征子集

LVM算法



## 嵌入式选择

将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成。

优化目标：
$$
\min_w \sum_{i=1}^m(y_i- w^{\top}x_i)^2
$$
岭回归：
$$
\min_w \sum_{i=1}^m(y_i- w^{\top}x_i)^2 + \lambda ||w||_2^2
$$
LASSO：
$$
\min_w \sum_{i=1}^m(y_i- w^{\top}x_i)^2+ \lambda||w||_1
$$


## 稀疏表示与字典学习

[参考链接](https://zhuanlan.zhihu.com/p/26015351)



字典学习：

1. 对庞大数据集的一种降维表示(信息压缩)
2. 总是常识学习蕴藏在样本背后最质朴的特征
3. 侧重于学得字典的过程



稀疏编码：

1. 侧重于对样本进行稀疏表达的过程
2. 用尽可能少的资源表示尽可能多的知识（使得计算速度快）



## 压缩感知

[参考链接](https://zhuanlan.zhihu.com/p/22445302)