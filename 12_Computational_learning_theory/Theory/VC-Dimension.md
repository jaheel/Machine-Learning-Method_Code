# VC-Dimension

学习链接： https://tangshusen.me/2018/12/09/vc-dimension/

现实学习任务所面临的通常是无限假设空间，欲进行可学习性研究，需度量假设空间的复杂度。最常见的办法是考虑假设空间的”VC维“



VC维的泛化误差界是分布无关、数据独立的，也就是说，对任何数据分布都独立，使得基于VC维的可学习性分析结果具有一定的”普适性“。



## growth function

增长函数



对所有$m \in \mathbb N$ ，假设空间$H$的增长函数$\prod_H(m)$为：
$$
\prod_H(m)= \max_{\{x_1,...,x_m\} \subseteq X}|\{ (h(x_1),...,h(x_m))| h \in H \}|
$$

> 表示假设空间$H$对m个示例所能赋予标记的最大可能结果数



尽管$H$可能包含无穷多个假设，但其对D中示例赋予标记的可能结果数是有限的：对$m$个示例，最多有$2^m$个可能结果。

## dichotomy

对分



对二分类问题来说，$H$中的假设对D中示例赋予标记的每种可能结果称为对D的一种”对分“。

## shattering

打散



若假设空间$H$能实现示例集D上的所有对分，即$\prod_H(m)=2^m$，则称示例集D能被假设空间$H$”打散“。



## VC-Dimension

假设空间$H$的VC维是能被$H$打散的最大示例集的大小，即
$$
VC(H)=max\{ m: \prod_H(m)=2^m \}
$$


Sauer引理：

若假设空间$H$的VC维为$d$，则对任意$m \in \mathbb N$有：
$$
\prod_H(m) \le \sum_{i=0}^d \dbinom{m}{i}
$$


上面可推论出：

若假设空间$H$的VC维为$d$，则对任意整数$m \ge d$有：
$$
\prod_H(m) \le (\frac{e \cdot m}{d})^d
$$


定理12.4 : 任何VC维有限的假设空间$H$都是（不可知）PAC可学习的。

